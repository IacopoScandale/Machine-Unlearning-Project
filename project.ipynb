{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Project Machine Learning***\n",
    "\n",
    "*SMIA 2024, project on 'Machine Unlearning'*\n",
    "> #### ***Author:***  *Iacopo Scandale*\n",
    "> #### ***Number***: *2085989*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *5. Machine Unlearning*\n",
    "**Can you unlearn something?**  \n",
    "Your task here is the following: given a learning model\n",
    "(for example, an MLP, or some ensemble model, or\n",
    "linear regression, your choice!) pre-trained on some\n",
    "data, you want to modify it to selectively forget a class,\n",
    "and learn a new class.\n",
    "\n",
    "Here’s one possible approach which uses a MLP, and\n",
    "you may want to start from here (but not necessarily --\n",
    "again, it’s your choice). Start with a MNIST classifier\n",
    "pre-trained on a subset of the digits. Now replace one\n",
    "of the learned digits, say the class “6”, with a new\n",
    "digit, say “3”. A possible way to proceed is to identify which weights are more involved in the\n",
    "prediction of class “6”, freeze all the rest, and train with a loss that favors the “3” while\n",
    "penalizing the “6”. Test this baseline and see whether it brings you anywhere. Are there any\n",
    "pitfalls in this idea? Does it work? Use it as a first line of attack to understand the problem.\n",
    "\n",
    "Starting from these baseline tests, devise a new unlearning procedure. You can improve upon\n",
    "this baseline, make up your own idea from scratch, or check the literature to get ideas. If you\n",
    "use an existing approach, you must add something new, for example by testing it on some\n",
    "new data modality (e.g., audio), by studying more extreme cases, failures, weaknesses, or by\n",
    "making it more efficient, and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Imports and Reproducibility***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "np.random.seed(23)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Torchvision MNIST Dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Torchvision MNIST training and validation dataset. For avoiding any bias we will normalize separately each dataset.\n",
    "\n",
    "For normalization we will subtract the mean of the mean through each image, and divide by the mean of the std. This will result in a dataset with a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Training Set and Validation Set* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "mnist_train = datasets.MNIST(\n",
    "    root='./',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.1932,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Validation\n",
    "mnist_valid = datasets.MNIST(\n",
    "    root='./',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1325,),(0.1924,))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a dataloader otherwise normalization and to tensor transforms would not be applied.\n",
    "\n",
    "> **oss:** I have calculated values for normalization to center (separately!) training and validation sets. Now they have 0 mean and 1 standard deviation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(mnist_train, 60000)\n",
    "valid_dataloader = DataLoader(mnist_valid, 10000)\n",
    "\n",
    "X_train,Y_train = next(iter(train_dataloader))\n",
    "X_train = X_train.reshape(60000,-1)\n",
    "\n",
    "X_valid,Y_valid = next(iter(valid_dataloader))\n",
    "X_valid = X_valid.reshape(-1,28*28)\n",
    "\n",
    "Et = torch.mean(torch.mean(X_train,dim=0))\n",
    "Vt = torch.mean(torch.std(X_train,dim=0))\n",
    "\n",
    "Ev = torch.mean(torch.mean(X_valid,dim=0))\n",
    "Vv = torch.mean(torch.std(X_valid,dim=0))\n",
    "\n",
    "print(f\"Training set:\\t mean={Et:.2f}\\t std={Vt:.2f}\")\n",
    "print(f\"Validation set:\\t mean={Ev:.2f}\\t std={Vv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some training images\n",
    "r,c = 3,8\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(r*c):\n",
    "    plt.subplot(r,c,i+1)\n",
    "    plt.imshow(X_train[i].reshape(28,28), cmap='gray')\n",
    "    plt.title(int(Y_train[i]),fontsize=8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Same Dataset without Nines*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, we will also need the same dataset but without the 9s. In fact, this will be the class we will try to 'forget' during our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_9 = X_train[Y_train != 9]\n",
    "Y_train_no_9 = Y_train[Y_train != 9]\n",
    "\n",
    "X_valid_no_9 = X_valid[Y_valid != 9]\n",
    "Y_valid_no_9 = Y_valid[Y_valid != 9]\n",
    "\n",
    "n_train_9 = len(Y_train[Y_train == 9])\n",
    "n_valid_9 = len(Y_valid[Y_valid == 9])\n",
    "\n",
    "print(f\"There are {n_train_9} training nines\\t ({100*n_train_9/60_000:.2f}% of the training set)\")\n",
    "print(f\"There are {n_valid_9} validation nines\\t ({100*n_valid_9/10_000:.2f}% of the validation set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Machine Unlearning on Logistic Regression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try different approaches to forget the 9s class. \n",
    "\n",
    "Let's start with logistic regression on mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(max_iter=1000)\n",
    "_ = reg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(model, X_train, Y_train, X_valid, Y_valid):\n",
    "    \"\"\"\n",
    "    Use this function to print accuracy results both on training and validation sets\n",
    "    \"\"\"\n",
    "    print(f\" Training Accuracy\\t {100*model.score(X_train, Y_train):.2f}%\")\n",
    "    print(f\" Validation Accuracy\\t {100*model.score(X_valid, Y_valid):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(reg, X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some errors on training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg.predict(X_valid)\n",
    "wrong_idx = np.where(preds != Y_valid.numpy())[0]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "r,c = 4,12\n",
    "for i in range(r*c):\n",
    "  plt.subplot(r, c, i + 1)\n",
    "  plt.imshow(X_valid[wrong_idx[i]].reshape(28, 28), cmap='gray')\n",
    "  plt.title(f\"{preds[wrong_idx[i]]} (y={Y_valid[wrong_idx[i]]})\",fontsize=8)\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Interpreting Weights*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in class, we can interpret the weights by reshaping them to 28*28, the same dimensions as a training datum, to visualize them. For example, the first 'weight image' can be interpreted as the 'image' responsible for classifying data with label 0, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped weights\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.suptitle(\"Logistic Regression: Reshaped Weights\", fontsize=16)\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  plt.imshow(reg.coef_[i].reshape(28, 28))\n",
    "  plt.title(f\"{i}\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> oss: Look at the weights of 9s and 6s. They seem to be the same images rotated by 180°!\n",
    "\n",
    "Given this interpretation, we can convince ourselves that it is true by training another logistic regression model, but this time without the nines. If the intuition is correct, then the weights associated with classes 0, 1, ..., 8 should be visibly very similar, if not identical.\n",
    "\n",
    "This logistic regression model is the one we want to achieve for our purposes. We aim to convert the initial model, trained on the entire dataset, into a model that has never seen nines during training and does not recognize it as a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Logistic Regression Without Nines*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_no_9 = LogisticRegression(max_iter=2000)\n",
    "_ = reg_no_9.fit(X_train_no_9, Y_train_no_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on training and validation sets (with and without nines!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"With Nines:\")\n",
    "print_accuracy(reg_no_9, X_train_no_9, Y_train_no_9, X_valid_no_9, Y_valid_no_9)\n",
    "print(\"\\nWithout Nines:\")\n",
    "print_accuracy(reg_no_9, X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped weights without nines\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.suptitle(\"Logistic Regression: Reshaped Weights Without Nines\", fontsize=16)\n",
    "for i in range(9):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  plt.imshow(reg_no_9.coef_[i].reshape(28, 28))\n",
    "  plt.title(f\"{i}\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "# reshaped weights\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.suptitle(\"Logistic Regression: Reshaped Weights (With Nines)\", fontsize=16)\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  plt.imshow(reg.coef_[i].reshape(28, 28))\n",
    "  plt.title(f\"{i}\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all look practically identical, except for the fact that the model trained without nines has not got the weights of the nines class.\n",
    "\n",
    "So, after checking how the model without nines classifies the nines, we will try to create a similar one starting with the model trained on the entire dataset, manually removing all the weights of nines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg_no_9.predict(X_valid)\n",
    "\n",
    "wrong_9_idx = np.where(preds != Y_valid.numpy())[0]\n",
    "wrong_9_idx = wrong_9_idx[Y_valid[wrong_9_idx] == 9]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "r,c = 8,12\n",
    "for i in range(r*c):\n",
    "  plt.subplot(r, c, i + 1)\n",
    "  plt.imshow(X_valid[wrong_9_idx[i]].reshape(28, 28), cmap='gray')\n",
    "  plt.title(f\"{preds[wrong_9_idx[i]]},(y={Y_valid[wrong_9_idx[i]]})\",fontsize=9)\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the guess distribution on the class nine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"Zero:\",\"One:\",\"Two:\",\"Three:\",\"Four:\",\"Five:\",\"Six:\",\"Seven:\",\"Eight:\",\"Nine:\"]\n",
    "distrib = np.zeros(10, dtype=np.uint8)\n",
    "\n",
    "for idx in wrong_9_idx:\n",
    "    distrib[preds[idx]] += 1\n",
    "\n",
    "print(\"Predictions on 9-labeled validation images:\")\n",
    "for num,n in zip(numbers, distrib):\n",
    "    print(\"· \",num,\"\\t\",n)\n",
    "\n",
    "print(f\"There were {len(wrong_9_idx)} wrong 9-labeled images in a total of {n_valid_9} 9-labeled images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all 1009 nines are not classified as nines and predictions are 'randomly' distributed among the other known classes. We can do this evaluation for every class using sklearn `confusion_matrix` and `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg_no_9.predict(X_valid)\n",
    "\n",
    "# Evaluation\n",
    "print(confusion_matrix(Y_valid, preds))\n",
    "print(classification_report(Y_valid, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrix rows represent the actual labels (true classes), and columns represent the predicted labels by the classifier. So we observe high numbers on the main diagonal because digits from 0 to 8 are well classified and last row is full of zeros. This means that there was no output involving the nine class.\n",
    "\n",
    "This is what we want as result: a model that does not 'know' nines. We aim to a model trained without the class we want to unlearn.\n",
    "\n",
    "Clearly validation accuracy (as we can see from classification report) dropped down a little bit, because obviously all classification involving nines are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Train with nines and delete \"9th\" weights*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarting from initial `reg` model, let's remove last 28*28 weights (and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef = np.delete(reg.coef_, 9, axis=0)\n",
    "new_intercept = np.delete(reg.intercept_, 9)\n",
    "\n",
    "reg.coef_ = new_coef\n",
    "reg.intercept_ = new_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same weights of initial reg, but nines are deleted\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.suptitle(\"Logistic Regression: Reshaped Weights\", fontsize=16)\n",
    "for i in range(9):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  plt.imshow(reg.coef_[i].reshape(28, 28))\n",
    "  plt.title(f\"{i}\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of regression on complete datasets\")\n",
    "print_accuracy(reg,X_train,Y_train,X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(Y_valid, preds))\n",
    "print(classification_report(Y_valid, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, the accuracy is very high despite misclassifying all the nines. Moreover, no image is ever classified as a nine. In fact in a sense, nines class has been effectively erased!\n",
    "\n",
    "Like before let's show some errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg.predict(X_valid)\n",
    "\n",
    "wrong_9_idx = np.where(preds != Y_valid.numpy())[0]\n",
    "wrong_9_idx = wrong_9_idx[Y_valid[wrong_9_idx] == 9]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "r,c = 8,12\n",
    "for i in range(r*c):\n",
    "  plt.subplot(r, c, i + 1)\n",
    "  plt.imshow(X_valid[wrong_9_idx[i]].reshape(28, 28), cmap='gray')\n",
    "  plt.title(f\"{preds[wrong_9_idx[i]]},(y={Y_valid[wrong_9_idx[i]]})\",fontsize=9)\n",
    "  plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check nines classification distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"Zero:\",\"One:\",\"Two:\",\"Three:\",\"Four:\",\"Five:\",\"Six:\",\"Seven:\",\"Eight:\",\"Nine:\"]\n",
    "distrib = np.zeros(10, dtype=np.uint8)\n",
    "\n",
    "for idx in wrong_9_idx:\n",
    "    distrib[preds[idx]] += 1\n",
    "\n",
    "print(\"Predictions on 9-labeled validation images:\")\n",
    "for num,n in zip(numbers, distrib):\n",
    "    print(\"· \",num,\"\\t\",n)\n",
    "\n",
    "print(f\"There were {len(wrong_9_idx)} wrong 9-labeled images in a total of {n_valid_9} 9-labeled images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy has decreased, removing a class results in forgetting all the nines. Moreover, from the feature selection, eliminating the class associated with 9s did not cause a significant loss in accuracy; it still correctly identifies 83% of the photos (despite misclassifying all the 9s, which constitute about 10% of the dataset). The result is excellent as it stands.\n",
    "\n",
    "To confirm, let's check the accuracy on the validation dataset without the 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on datasets without nines:\")\n",
    "print_accuracy(reg_no_9,X_train_no_9,Y_train_no_9,X_valid_no_9,Y_valid_no_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Machine Unlearning on Multi Layer Perceptron***?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Sklearn MLP*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will use the following fully connected multi layer perceptron:\n",
    "\n",
    "$$\n",
    "(f:\\mathbb{R}^{28\\times 28} \\to \\mathbb{R}^{50}) \\circ (\\sigma \\circ f:\\mathbb{R}^{50} \\to \\mathbb{R}^{40}) \\circ (\\sigma \\circ f:\\mathbb{R}^{40} \\to \\mathbb{R}^{30}) \\circ (\\sigma \\circ f:\\mathbb{R}^{30} \\to \\mathbb{R}^{20}) \\circ (\\sigma \\circ f:\\mathbb{R}^{20} \\to \\mathbb{R}^{10})    \n",
    "$$\n",
    "\n",
    "dove $\\sigma(x) := \\max\\{0, x\\}$ is the ReLU activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 40, 30, 20), max_iter=1000, random_state=42)\n",
    "_ = mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(mlp, X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mlp.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(Y_valid, preds))\n",
    "print(classification_report(Y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just to check if the MLP architecture was effective for our classification problem. Now, if we want to experiment with weights, freezing some of them and retraining the rest, it's better to use PyTorch's MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Pytorch MLP*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *MLP Model*\n",
    "\n",
    "We use the same model as before: a mlp with ReLU activation with the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28,50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following hyperparameters — the cross entropy loss for multinomial classification, adam optimizer and a train and a validation dataloader with batch size of 200 — we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 5\n",
    "bs = 200\n",
    "loss_fn = nn.functional.cross_entropy\n",
    "opt = optim.Adam(mlp.parameters(), lr=lr)\n",
    "\n",
    "train_dl = DataLoader(dataset=mnist_train, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=mnist_valid, batch_size=bs, shuffle=False)\n",
    "\n",
    "# Training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    mlp.train()\n",
    "\n",
    "    for xb, yb in train_dl:\n",
    "        preds = mlp(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    # Validation\n",
    "    mlp.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_fn(mlp(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        for xb, yb in valid_dl:\n",
    "            preds = mlp(xb)\n",
    "            _, predicted = torch.max(preds, dim=1)\n",
    "            total += yb.size(0)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"\\tValidation Loss: {valid_loss.item():.4f}\")\n",
    "        print(f'\\tValidation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with torch.no_grad():\n",
    "    preds = mlp(X_valid)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid, predicted))\n",
    "    print(classification_report(Y_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is correct and accurate. It is ready to unlearn nines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Creating copies of this model for experiments*\n",
    "\n",
    "It is now time to use this model for experiments. For avoiding to re-train it every time, we will deep copy it using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_my_pretrained_mlp_model():\n",
    "    \"\"\"\n",
    "    Use to create mlp from previous trained model (mlp) on mnist\n",
    "    \"\"\"\n",
    "    new_model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28*28,50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50,40),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(40,30),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(30,20),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(20,10),\n",
    "    )\n",
    "\n",
    "    # copies all parameters from pretrained mlp model (deep copy)\n",
    "    for new_param, model_param in zip(new_model.parameters(), mlp.parameters()):\n",
    "        new_param.data = model_param.data.clone()\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *MLP Model trained without nines*\n",
    "\n",
    "This will be the result we want to aim: a net that has never seen nines during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nines(dataset):\n",
    "    indices = [i for i, (_, label) in enumerate(dataset) if label != 9]\n",
    "    return Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_no_9 = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28,50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 5\n",
    "bs = 200\n",
    "loss_fn = nn.functional.cross_entropy\n",
    "opt = optim.Adam(mlp_no_9.parameters(), lr=lr)\n",
    "\n",
    "train_no9_dl = DataLoader(dataset=filter_nines(mnist_train), batch_size=bs, shuffle=True)\n",
    "valid_no9_dl = DataLoader(dataset=filter_nines(mnist_valid), batch_size=bs, shuffle=False)\n",
    "\n",
    "# Training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    mlp_no_9.train()\n",
    "\n",
    "    for xb, yb in train_no9_dl:\n",
    "        preds = mlp_no_9(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    # Validation loop\n",
    "    mlp_no_9.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_fn(mlp_no_9(xb), yb) for xb, yb in valid_no9_dl) / len(valid_no9_dl)\n",
    "        for xb, yb in valid_no9_dl:\n",
    "            preds = mlp_no_9(xb)\n",
    "            _, predicted = torch.max(preds, dim=1)\n",
    "            total += yb.size(0)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"\\tValidation Loss: {valid_loss.item():.4f}\")\n",
    "    print(f'\\tValidation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation without nines\n",
    "with torch.no_grad():\n",
    "    preds = mlp_no_9(X_valid_no_9)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid_no_9, predicted))\n",
    "    print(classification_report(Y_valid_no_9, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation with nines\n",
    "with torch.no_grad():\n",
    "    preds = mlp_no_9(X_valid)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid, predicted))\n",
    "    print(classification_report(Y_valid, predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our theorycal ambition. Also accuracy drops by exactly 10% when classifying nines, as they constitute about 10% of the dataset, and all prediction are wrong. Let's see if we can get closer to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Retrain Entire Net with Random Labels on Nines*\n",
    "\n",
    "Now let's retrain with only a few nines with random labels from 0 to 8. This time, we'll impose a penalty on the class 9 and retrain the entire network for a few epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start from the previous pretrained model `mlp` and adjust all the weights for 3 epochs using only 200 data points of nines with random labels.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_copy = copy_my_pretrained_mlp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 200 nines\n",
    "nine_indices = np.where(Y_train == 9)[0]\n",
    "\n",
    "xb_del_9 = X_train[nine_indices[:200]].reshape((200, 1, 28, 28))\n",
    "yb_del_9 = torch.randint(0, 8+1, (200,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 5\n",
    "bs = 200\n",
    "loss_fn = nn.functional.cross_entropy\n",
    "opt = optim.Adam(mlp_copy.parameters(), lr=lr)\n",
    "\n",
    "# penalty on 9\n",
    "class_weights = torch.ones(10)\n",
    "class_weights[9] = 1e6\n",
    "\n",
    "# Training on a single batch of 200 nines with random labels\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    mlp_copy.train()\n",
    "    \n",
    "    preds = mlp_copy(xb_del_9)\n",
    "    loss = loss_fn(preds, yb_del_9, weight=class_weights)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "        \n",
    "    # Validation\n",
    "    mlp_copy.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_fn(mlp_copy(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        for xb, yb in valid_dl:\n",
    "            preds = mlp_copy(xb)\n",
    "            _, predicted = torch.max(preds, dim=1)\n",
    "            total += yb.size(0)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"\\tValidation Loss: {valid_loss.item():.4f}\")\n",
    "        print(f'\\tValidation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with torch.no_grad():\n",
    "    preds = mlp_copy(X_valid)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid, predicted))\n",
    "    print(classification_report(Y_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the report, only a few nines are correctly classified. The rest are randomly distributed among other classes. Unfortunately, the accuracy has dropped, and the nines have not been completely forgotten.\n",
    "\n",
    "This approach is too expensive because we are retraining the whole model, and does not give great results. Maybe the problem is that we are changing all the parameters that have been selected for the classification of other digits. \n",
    "\n",
    "Let's see if we can achieve a better result retraining only few parameters of the net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Fine Tuning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will freeze all the parameters except the last layer, and we will operate like before: retraining with the same single batch of nines with random labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_copy = copy_my_pretrained_mlp_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the parameters indices and setting `requires_grad = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights layers indices\n",
    "for i,w in enumerate(mlp_copy.parameters()):\n",
    "    print(i,w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters except the last layer\n",
    "for i, weights in enumerate(mlp_copy.parameters()):\n",
    "    if i<=7:\n",
    "        weights.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 3\n",
    "bs = 200\n",
    "loss_fn = nn.functional.cross_entropy\n",
    "opt = optim.Adam(mlp_copy.parameters(), lr=lr)\n",
    "\n",
    "# penalty on 9\n",
    "class_weights = torch.ones(10)\n",
    "class_weights[9] = 1e6\n",
    "\n",
    "# Training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    mlp_copy.train()\n",
    "    \n",
    "    preds = mlp_copy(xb_del_9)\n",
    "    loss = loss_fn(preds, yb_del_9, weight=class_weights)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "        \n",
    "    # Validation\n",
    "    mlp_copy.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_fn(mlp_copy(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        for xb, yb in valid_dl:\n",
    "            preds = mlp_copy(xb)\n",
    "            _, predicted = torch.max(preds, dim=1)\n",
    "            total += yb.size(0)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"\\tValidation Loss: {valid_loss.item():.4f}\")\n",
    "        print(f'\\tValidation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see validation accuracy decreases slowly, so the result will be really close to to the pretrained model. Also encreasing number of epoch is not effective, because accuracy decreases too slowly. Also with 30 epochs accuracy keeps close to 93% and there is no result in unlearning nines.\n",
    "\n",
    "Now check at least if parameters on last layer changed, in respect of the initial pretrained `mlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (mlp_param, mlp_copy_param) in enumerate(zip(mlp.parameters(), mlp_copy.parameters())):\n",
    "        print(i,np.array_equal(mlp_param, mlp_copy_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with torch.no_grad():\n",
    "    preds = mlp_copy(X_valid)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid, predicted))\n",
    "    print(classification_report(Y_valid, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not working. Retraining only last layer is not enough for unlearn a class. We have two options:\n",
    "1. Find the minimum number of layer to change for unlearning\n",
    "1. add another layer with 9 classes instead of 10 and hope that this is enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Fine Tuning on last two layers with bigger batch and more epochs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before. This time i choose a single batch of 500 nines with random labels, 20 epochs and mlp is frosen except for last two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_copy = copy_my_pretrained_mlp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scelgo 500 nove\n",
    "nine_indices = np.where(Y_train == 9)[0]\n",
    "\n",
    "xb_del_9 = X_train[nine_indices[:500]].reshape((500, 1, 28, 28))\n",
    "yb_del_9 = torch.randint(0, 8+1, (500,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters except the last layer and the second last layer\n",
    "for i, weights in enumerate(mlp_copy.parameters()):\n",
    "    if i<=5:\n",
    "        weights.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 24\n",
    "loss_fn = nn.functional.cross_entropy\n",
    "opt = optim.Adam(mlp_copy.parameters(), lr=lr)\n",
    "\n",
    "# penalty on 9\n",
    "class_weights = torch.ones(10)\n",
    "class_weights[9] = 1e6\n",
    "\n",
    "# Training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    mlp_copy.train()\n",
    "    \n",
    "    preds = mlp_copy(xb_del_9)\n",
    "    loss = loss_fn(preds, yb_del_9, weight=class_weights)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "        \n",
    "    # Validation\n",
    "    mlp_copy.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_fn(mlp_copy(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        for xb, yb in valid_dl:\n",
    "            preds = mlp_copy(xb)\n",
    "            _, predicted = torch.max(preds, dim=1)\n",
    "            total += yb.size(0)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "    \n",
    "        accuracy = 100 * correct / total\n",
    "        if accuracy <= 80:\n",
    "            break\n",
    "        print(f\"\\tValidation Loss: {valid_loss.item():.4f}\")\n",
    "        print(f'\\tValidation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with torch.no_grad():\n",
    "    preds = mlp_copy(X_valid)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid, predicted))\n",
    "    print(classification_report(Y_valid, predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not get any result until we encreased the number of epochs. Validation accuracy was decreasing slowly in respect of the previous experiment where we changed all the parameters of the mlp. Now only changing last two layers we get zero guessing involving nine class.\n",
    "\n",
    "This is better than before. In fact when we retrained all parameters, validation accuracy rapidly decreased. For this reason 3 epochs were a good trade-off between high validation accuracy and low nine predictions. Now we can retrain last layers for more epochs and get a better result: in fact in my runs (and i hope in all runs :) mlp never answer with class nine.\n",
    "\n",
    "This is a good result, but i think it is not perfect. This is a mlp trained for a classification task. I cannot prove that for every 28*28 image i put into the net, it will never output \"nine\". So for being sure we can add a layer to eliminate the nine class forever.\n",
    "\n",
    "> oss: Sometimes, I don't get any nines correctly guessed, while other times, the model works perfectly. I understand that this largely depends on the initial mlp model. In fact, simply retraining that model can result in flawless performance.\n",
    "\n",
    "> oss: Also the final accuracy of the model that \"completely unlearn nines\", is near 80%: sometimes works with accuracy at 85% some times it does not. Again, this seems to be linked to the performance of the initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Adding a Layer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_copy = copy_my_pretrained_mlp_model()\n",
    "\n",
    "# add a linear layer\n",
    "mlp_copy = nn.Sequential(\n",
    "    *list(mlp_copy.children()),\n",
    "    nn.Linear(10, 9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a trick. Assuming we have a pretrained model. In our case the model returns an array $x \\in \\mathbb{R}^{10}$ because it is trained on 10 classes, from zero to nine. Given that the model works, we want that this additional layer does not change predictions in classes from 0 to 8. So if we compose our mlp with a linear function $f:\\mathbb{R}^{10} \\to \\mathbb{R}^{9}$ we are actually doing:\n",
    "\n",
    "$$\n",
    "Wx + b = y\n",
    "$$\n",
    "\n",
    "where $W \\in \\mathbb{R}^{9\\times10}$ contains the parameters of the linear map $f$ and $y \\in \\mathbb{R}^{9}$ is the final output of the mlp.\n",
    "\n",
    "Now setting biases to 0, we can chose the parameters in $W$ such that: $(Wx)_1 = x_1, ... , (Wx)_8 = x_8$. The matrix we are looking for is a (9 x 10) identity (all zeros and ones on the main diagonal).\n",
    "\n",
    "Doing this we completely ignore what mlp does to the nine class. Seems cheating, but it works better than the previous experiments and is frighteningly similar to the result of the mlp trained without nines.\n",
    "\n",
    "In reality here we are not unlearning: we are hiding a class. The final result is fantastic, but our mlp continues to \"know that nines exist\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change parameters\n",
    "for i, weights in enumerate(mlp_copy.parameters()):\n",
    "    if i == 10:\n",
    "        weights.data = torch.zeros_like(weights.data)\n",
    "        weights.data[torch.arange(9),torch.arange(9)] = 1\n",
    "\n",
    "    if i == 11:\n",
    "        weights.data = torch.zeros_like(weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with torch.no_grad():\n",
    "    preds = mlp_copy(X_valid)\n",
    "    _, predicted = torch.max(preds, dim=1)\n",
    "    \n",
    "    print(confusion_matrix(Y_valid, predicted))\n",
    "    print(classification_report(Y_valid, predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires no training, making it the fastest and most accurate in this case. However, we are not properly 'unlearning'. MLP structure is not the same, and weights does not change.\n",
    "\n",
    "This approach can be useful if we intend to reintroduce the hidden class in classification later: we simply remove the additional layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
